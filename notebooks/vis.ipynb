{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manten.data.dataset_maniskill import ManiSkillDataset\n",
    "\n",
    "cameras = [\"camera1\", \"gripper1\"]\n",
    "# cameras = [\"camera1\"]\n",
    "dataset = ManiSkillDataset(\n",
    "    simulated_length=10000000,\n",
    "    test_ratio=0.05,\n",
    "    task=\"PegInsertionSide-v1\",\n",
    "    # task=\"PickCube-v1\",\n",
    "    pack_root=\"/home/i53/student/yagmurlu/code/manten/manten_evaluation/maniskill2/data/maniskill2/packed_demos\",\n",
    "    obs_horizon=2,\n",
    "    pred_horizon=16,\n",
    "    obs_mode=\"pointcloud\",\n",
    "    state_modality_keys=[\"tcp_pose\"],\n",
    "    rgb_modality_keys=cameras,\n",
    "    control_mode=\"pd_ee_delta_pose\",\n",
    "    # control_mode=\"pd_ee_delta_pose\",\n",
    "    use_mmap=True,\n",
    "    # use_mmap=False,\n",
    "    rotation_transform=\"rotation_6d\",\n",
    "    load_count=2,\n",
    ")\n",
    "\n",
    "# print(dataset[0])\n",
    "\n",
    "dataset_info = dataset.get_dataset_info()\n",
    "\n",
    "print(dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optree\n",
    "\n",
    "fi = dataset[0]\n",
    "\n",
    "optree.tree_map(lambda x: x.shape, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "episode_idx = 25\n",
    "\n",
    "data = optree.tree_map(lambda x: torch.tensor(x), dataset.get_episode(episode_idx))\n",
    "\n",
    "mask = data[\"observations\"][\"pcd_mask\"]\n",
    "masked_zeroed_rgb_obs = optree.tree_map(\n",
    "    lambda x, m: x * m, data[\"observations\"][\"rgb_obs\"], mask\n",
    ")\n",
    "masked_zeroed_pcd_obs = optree.tree_map(\n",
    "    lambda x, m: x * m, data[\"observations\"][\"pcd_obs\"], mask\n",
    ")\n",
    "\n",
    "print(len(masked_zeroed_rgb_obs[\"camera1\"]))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 30))\n",
    "fig.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Remove margins\n",
    "axs[0].axis(\"off\")\n",
    "axs[1].axis(\"off\")\n",
    "step = 10\n",
    "\n",
    "\n",
    "def update(ix, ax):\n",
    "    ix = ix * step\n",
    "    rgb_obs = to_pil_image(\n",
    "        einops.rearrange(\n",
    "            [masked_zeroed_rgb_obs[\"camera1\"][ix]],\n",
    "            # [masked_zeroed_rgb_obs[cam][ix] for cam in cameras],\n",
    "            \"cam c h w -> c (cam h) w\",\n",
    "        )\n",
    "    )\n",
    "    # pcd_obs = (\n",
    "    #     einops.rearrange(\n",
    "    #         [masked_zeroed_pcd_obs[cam][ix] for cam in cameras],\n",
    "    #         \"cam c h w -> c (cam h) w\",\n",
    "    #     )\n",
    "    # ).permute(1, 2, 0) * 0.5 + 0.5\n",
    "    # pcd_mask = to_pil_image(\n",
    "    #     einops.rearrange(\n",
    "    #         [mask[cam][ix] for cam in cameras],\n",
    "    #         \"cam c h w -> c (cam h) w\",\n",
    "    #     ).float()\n",
    "    # )\n",
    "\n",
    "    axs[ax].imshow(rgb_obs)\n",
    "    # axs[1].imshow(pcd_obs)\n",
    "    # axs[2].imshow(pcd_mask)\n",
    "    return axs\n",
    "\n",
    "\n",
    "# ani = animation.FuncAnimation(fig, update, frames=len(masked_zeroed_rgb_obs[\"camera1\"])//step, blit=False)\n",
    "# from IPython.display import HTML\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "update(0, 0)\n",
    "update(2, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "episode_idx = 25\n",
    "\n",
    "data = optree.tree_map(lambda x: torch.tensor(x), dataset.get_episode(episode_idx))\n",
    "\n",
    "mask = data[\"observations\"][\"pcd_mask\"]\n",
    "masked_zeroed_rgb_obs = optree.tree_map(\n",
    "    lambda x, m: x * m, data[\"observations\"][\"rgb_obs\"], mask\n",
    ")\n",
    "masked_zeroed_pcd_obs = optree.tree_map(\n",
    "    lambda x, m: x * m, data[\"observations\"][\"pcd_obs\"], mask\n",
    ")\n",
    "\n",
    "print(len(masked_zeroed_rgb_obs[\"camera1\"]))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 10))\n",
    "fig.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Remove margins\n",
    "axs[0].axis(\"off\")\n",
    "axs[1].axis(\"off\")\n",
    "axs[2].axis(\"off\")\n",
    "step = 10\n",
    "\n",
    "\n",
    "def update(ix):\n",
    "    ix = ix * step\n",
    "    rgb_obs = to_pil_image(\n",
    "        einops.rearrange(\n",
    "            [masked_zeroed_rgb_obs[cam][ix] for cam in cameras],\n",
    "            \"cam c h w -> c (cam h) w\",\n",
    "        )\n",
    "    )\n",
    "    pcd_obs = (\n",
    "        einops.rearrange(\n",
    "            [masked_zeroed_pcd_obs[cam][ix] for cam in cameras],\n",
    "            \"cam c h w -> c (cam h) w\",\n",
    "        )\n",
    "    ).permute(1, 2, 0) * 0.5 + 0.5\n",
    "    pcd_mask = to_pil_image(\n",
    "        einops.rearrange(\n",
    "            [mask[cam][ix] for cam in cameras],\n",
    "            \"cam c h w -> c (cam h) w\",\n",
    "        ).float()\n",
    "    )\n",
    "\n",
    "    axs[0].imshow(rgb_obs)\n",
    "    axs[1].imshow(pcd_obs)\n",
    "    axs[2].imshow(pcd_mask)\n",
    "    return axs\n",
    "\n",
    "\n",
    "# ani = animation.FuncAnimation(fig, update, frames=len(masked_zeroed_rgb_obs[\"camera1\"])//step, blit=False)\n",
    "# from IPython.display import HTML\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "update(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-base\")\n",
    "model = AutoModel.from_pretrained(\"facebook/dinov2-base\")\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "inputs.data[\"pixel_values\"] = F.interpolate(\n",
    "    inputs.data[\"pixel_values\"], size=(448, 448), mode=\"bicubic\"\n",
    ")\n",
    "\n",
    "inputs_processed = inputs.data[\"pixel_values\"].clone()\n",
    "\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs[0]\n",
    "\n",
    "# We have to force return_dict=False for tracing\n",
    "model.config.return_dict = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    traced_model = torch.jit.trace(model, [inputs.pixel_values])\n",
    "    traced_outputs = traced_model(inputs.pixel_values)\n",
    "\n",
    "print((last_hidden_states - traced_outputs[0]).abs().max())\n",
    "\n",
    "\n",
    "def get_dino_pca_feats(image):\n",
    "    global traced_model\n",
    "    traced_model = traced_model.to(\"cuda\")\n",
    "\n",
    "    inputs = processor(images=image, return_tensors=\"pt\", do_rescale=False)\n",
    "    inputs.data[\"pixel_values\"] = F.interpolate(\n",
    "        inputs.data[\"pixel_values\"], size=(448, 448), mode=\"bicubic\"\n",
    "    )\n",
    "\n",
    "    inputs.data[\"pixel_values\"] = inputs.data[\"pixel_values\"].to(\"cuda\")\n",
    "\n",
    "    # inputs_processed = inputs.data['pixel_values'].clone()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = traced_model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "\n",
    "    # We have to force return_dict=False for tracing\n",
    "\n",
    "    # print((last_hidden_states - traced_outputs[0]).abs().max())\n",
    "\n",
    "    # print image and it's features\n",
    "\n",
    "    print(last_hidden_states.shape)\n",
    "\n",
    "    wo_cls = last_hidden_states[:, 1:]\n",
    "    h, w = 32, 32\n",
    "    wo_cls = einops.rearrange(wo_cls, \"b p c -> (b p) c\")\n",
    "\n",
    "    # do pca with torch.pca_lowrank\n",
    "    U, S, V = torch.pca_lowrank(wo_cls, q=3)\n",
    "    wo_cls = wo_cls @ V[:, :3]\n",
    "    mins = wo_cls.amin(dim=[0])\n",
    "    maxs = wo_cls.amax(dim=[0])\n",
    "    wo_cls = (wo_cls - mins) / (maxs - mins) * 1.0\n",
    "\n",
    "    wo_cls = einops.rearrange(wo_cls, \"(b h w) c -> b c h w\", h=h, w=w)\n",
    "\n",
    "    return wo_cls.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def inv_scale_action(action, low, high):\n",
    "    \"\"\"Inverse of `clip_and_scale_action` without clipping.\"\"\"\n",
    "    return (action - 0.5 * (high + low)) / (0.5 * (high - low))\n",
    "\n",
    "\n",
    "def get_scattered_points(points, n_points=None, std=None):\n",
    "    if n_points is None:\n",
    "        n_points = 10\n",
    "    if std is None:\n",
    "        std = 0.001\n",
    "\n",
    "    exp_points = einops.repeat(points, \"b c -> (b n_points) c\", n_points=n_points)\n",
    "    noise = torch.randn_like(exp_points) * std\n",
    "\n",
    "    return noise + exp_points\n",
    "\n",
    "\n",
    "def get_scatter_trace(\n",
    "    pcd,\n",
    "    rgb,\n",
    "    mask,\n",
    "    special_points=None,\n",
    "    special_point_colors=None,\n",
    "    special_point_scatter_n_points=None,\n",
    "    special_point_scatter_std=None,\n",
    "):\n",
    "    pcd = pcd[mask]\n",
    "    rgb = rgb[mask]\n",
    "\n",
    "    x, y, z = pcd[:, 0], pcd[:, 1], pcd[:, 2]\n",
    "    r, g, b = rgb[:, 0], rgb[:, 1], rgb[:, 2]\n",
    "\n",
    "    # sort by z so that it stands above the rest\n",
    "    z, indices = torch.sort(z)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    r = r[indices]\n",
    "    g = g[indices]\n",
    "    b = b[indices]\n",
    "\n",
    "    if special_points is not None:\n",
    "        scattered = get_scattered_points(\n",
    "            special_points, special_point_scatter_n_points, special_point_scatter_std\n",
    "        )\n",
    "\n",
    "        x = torch.cat([x, scattered[:, 0]])\n",
    "        y = torch.cat([y, scattered[:, 1]])\n",
    "        z = torch.cat([z, scattered[:, 2]])\n",
    "\n",
    "        repeat_len = len(scattered) / len(special_points)\n",
    "        repeated_colors = einops.repeat(\n",
    "            special_point_colors, \"b c -> (b n_points) c\", n_points=repeat_len\n",
    "        )\n",
    "\n",
    "        r = torch.cat([r, repeated_colors[:, 0]])\n",
    "        g = torch.cat([g, repeated_colors[:, 1]])\n",
    "        b = torch.cat([b, repeated_colors[:, 2]])\n",
    "\n",
    "    color = [f\"rgb({int(r[i]*255)}, {int(g[i]*255)}, {int(b[i]*255)})\" for i in range(len(r))]\n",
    "\n",
    "    return x, y, z, color\n",
    "\n",
    "\n",
    "def render_masked_3d_scatter(x, y, z, color, frames=None):\n",
    "    scatter = go.Scatter3d(\n",
    "        x=x, y=y, z=z, mode=\"markers\", marker={\"size\": 3, \"color\": color, \"opacity\": 0.8}\n",
    "    )\n",
    "\n",
    "    if frames is not None:\n",
    "        layout = go.Layout(\n",
    "            scene={\n",
    "                \"xaxis\": {\"title\": \"X Axis\", \"range\": [-1, 1], \"autorange\": False},\n",
    "                \"yaxis\": {\"title\": \"Y Axis\", \"range\": [-1, 1], \"autorange\": False},\n",
    "                \"zaxis\": {\"title\": \"Z Axis\", \"range\": [-1, 1], \"autorange\": False},\n",
    "            },\n",
    "            scene_aspectmode=\"cube\",\n",
    "            margin={\"l\": 0, \"r\": 0, \"b\": 0, \"t\": 0},\n",
    "            height=750,\n",
    "            updatemenus=[\n",
    "                {\n",
    "                    \"buttons\": [\n",
    "                        {\"args\": [None], \"label\": \"Play\", \"method\": \"animate\"},\n",
    "                        {\n",
    "                            \"args\": [\n",
    "                                [None],\n",
    "                                {\n",
    "                                    \"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                                    \"mode\": \"immediate\",\n",
    "                                    \"transition\": {\"duration\": 0},\n",
    "                                },\n",
    "                            ],\n",
    "                            \"label\": \"Pause\",\n",
    "                            \"method\": \"animate\",\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "        frames = [\n",
    "            go.Frame(\n",
    "                data=[\n",
    "                    go.Scatter3d(\n",
    "                        x=x,\n",
    "                        y=y,\n",
    "                        z=z,\n",
    "                        mode=\"markers\",\n",
    "                        marker={\"size\": 3, \"color\": color, \"opacity\": 0.8},\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            for x, y, z, color in frames\n",
    "        ]\n",
    "        fig = go.Figure(data=[scatter], layout=layout, frames=frames)\n",
    "    else:\n",
    "        layout = go.Layout(\n",
    "            scene={\n",
    "                \"xaxis\": {\"title\": \"X Axis\"},\n",
    "                \"yaxis\": {\"title\": \"Y Axis\"},\n",
    "                \"zaxis\": {\"title\": \"Z Axis\"},\n",
    "            },\n",
    "            # scene_aspectmode=\"cube\",\n",
    "            margin={\"l\": 0, \"r\": 0, \"b\": 0, \"t\": 0},\n",
    "            height=750,\n",
    "        )\n",
    "        fig = go.Figure(data=[scatter], layout=layout)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "data = optree.tree_map(lambda x: torch.tensor(x), dataset.get_episode(episode_idx))\n",
    "# data = dataset[0]\n",
    "\n",
    "# goal_pos = data[\"observations\"][\"state_obs\"]  # shape: (obs_horizon, 3) (position)\n",
    "# goal_rgb = torch.tensor([0.0, 1.0, 0.0]).expand(goal_pos.shape)\n",
    "goal_pos = torch.zeros((0,))\n",
    "goal_rgb = torch.zeros((0,))\n",
    "\n",
    "tcp_pos = data[\"observations\"][\"state_obs\"][\"tcp_pose\"][\n",
    "    ..., :3\n",
    "]  # shape: (obs_horizon, 7) (position + quaternion)\n",
    "tcp_rgb = torch.tensor([1.0, 0.0, 0.0]).expand(tcp_pos.shape)\n",
    "\n",
    "delta_trajectory = data[\"actions\"][..., :3] * 0.1\n",
    "# delta_trajectory = data['actions'][..., :3]\n",
    "# delta_trajectory = inv_scale_action(data[\"actions\"][..., :3], -1, 1)\n",
    "\n",
    "# # cumsum only works for !target! delta, not delta with current position\n",
    "trajectory = torch.cat([tcp_pos[:1, :3], delta_trajectory], dim=0).cumsum(dim=0)\n",
    "trajectory_rgb = torch.tensor([0.0, 0.0, 1.0]).expand(trajectory.shape)\n",
    "# trajectory = torch.zeros((0,))\n",
    "# trajectory_rgb = torch.zeros((0,))\n",
    "\n",
    "mask = data[\"observations\"][\"pcd_mask\"]\n",
    "pcd = data[\"observations\"][\"pcd_obs\"]\n",
    "rgb = data[\"observations\"][\"rgb_obs\"]\n",
    "\n",
    "# clip_backbone, clip_normalize = load_clip()\n",
    "\n",
    "# # clip_norm_rgb = clip_normalize(rgb)\n",
    "# # clip = clip_backbone(rgb)\n",
    "# clip_norm_pcd = optree.tree_map(lambda x: clip_normalize(x), rgb)\n",
    "# clip_rgb = optree.tree_map(lambda x: clip_backbone(x)['res1'], rgb)\n",
    "# # clip_rgb is bsx6464x64 do pca to convert it to bsx3x64x64\n",
    "# b = clip_rgb['camera1'].shape[0]\n",
    "# h, w = 64, 64\n",
    "# pca_clip_rgb = optree.tree_map(lambda x: einops.rearrange(x, 'b c h w -> (b h w) c'), clip_rgb) # pca over batches too\n",
    "# # U, S, V = torch.pca_lowrank(pca_clip_rgb, q=3)\n",
    "# # pca_clip_rgb = pca_clip_rgb @ V[:, :3]  # Shape: (bsize * height * width, 3)\n",
    "# # pca_clip_rgb = einops.rearrange(pca_clip_rgb, '(b h w) c -> b c h w', b=1, h=h, w=w)\n",
    "# usv = optree.tree_map(lambda x: torch.pca_lowrank(x, q=3), pca_clip_rgb)\n",
    "# pca_clip_rgb = optree.tree_map(lambda x, usv: x @ usv[2][:, :3], pca_clip_rgb, usv)\n",
    "# pca_clip_rgb = optree.tree_map(lambda x: einops.rearrange(x, '(b h w) c -> b c h w', b=b, h=h, w=w), pca_clip_rgb)\n",
    "# # normalize channel values to [0, 1]\n",
    "# min_val = optree.tree_map(lambda x: x.amin(dim=[0,2,3], keepdim=True), pca_clip_rgb)\n",
    "# max_val = optree.tree_map(lambda x: x.amax(dim=[0,2,3], keepdim=True), pca_clip_rgb)\n",
    "# pca_clip_rgb = optree.tree_map(lambda x, min_val, max_val: (x - min_val) / (max_val - min_val) * 1.0, pca_clip_rgb, min_val, max_val)\n",
    "\n",
    "pca_clip_rgb = optree.tree_map(lambda x: get_dino_pca_feats(x), rgb)  # 32x32\n",
    "\n",
    "# upscale to 128x128\n",
    "pca_clip_rgb = optree.tree_map(\n",
    "    lambda x: F.interpolate(x, scale_factor=4, mode=\"bilinear\"), pca_clip_rgb\n",
    ")\n",
    "\n",
    "scale_factor = 0\n",
    "if scale_factor:\n",
    "    rgb = optree.tree_map(\n",
    "        lambda x: F.interpolate(x, scale_factor=1 / scale_factor, mode=\"bilinear\"), rgb\n",
    "    )\n",
    "    pcd = optree.tree_map(\n",
    "        lambda x: F.interpolate(x, scale_factor=1 / scale_factor, mode=\"bilinear\"), pcd\n",
    "    )\n",
    "    mask = optree.tree_map(\n",
    "        lambda x: -F.max_pool2d(-x.float(), kernel_size=scale_factor) > (1 / 2),\n",
    "        mask,\n",
    "    )\n",
    "    pca_clip_rgb = optree.tree_map(\n",
    "        lambda x: F.interpolate(x, scale_factor=1 / scale_factor, mode=\"bilinear\"),\n",
    "        pca_clip_rgb,\n",
    "    )\n",
    "\n",
    "\n",
    "mask = optree.tree_map(lambda x: einops.rearrange(x, \"b 1 h w -> b (h w)\"), mask)\n",
    "pcd = optree.tree_map(lambda x: einops.rearrange(x, \"b c h w -> b (h w) c\"), pcd)\n",
    "rgb = optree.tree_map(lambda x: einops.rearrange(x, \"b c h w -> b (h w) c\"), rgb)\n",
    "pca_clip_rgb = optree.tree_map(\n",
    "    lambda x: einops.rearrange(x, \"b c h w -> b (h w) c\"), pca_clip_rgb\n",
    ")\n",
    "\n",
    "combined_pcd = torch.cat([pcd[cam] for cam in pcd], dim=1)\n",
    "combined_rgb = torch.cat([rgb[cam] for cam in rgb], dim=1)\n",
    "combined_mask = torch.cat([mask[cam] for cam in mask], dim=1)\n",
    "combined_pca_clip_rgb = torch.cat([pca_clip_rgb[cam] for cam in pca_clip_rgb], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next 2 cells for animated pcd, 3rd for static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = []\n",
    "# for idx in range(0, len(pcd[\"camera1\"]), 5):\n",
    "#     x, y, z, color = get_scatter_trace(\n",
    "#         combined_pcd[idx],\n",
    "#         combined_rgb[idx],\n",
    "#         # torch.ones_like(mask[idx]),\n",
    "#         combined_mask[idx],\n",
    "#         # special_points=torch.cat([tcp_pos, trajectory, goal_pos[:1]], dim=0),\n",
    "#         # special_point_colors=torch.cat([tcp_rgb, trajectory_rgb, goal_rgb[:]], dim=0),\n",
    "#     )\n",
    "#     frames.append((x, y, z, color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = render_masked_3d_scatter(*frames[0], frames=frames[::1])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "x, y, z, color = get_scatter_trace(\n",
    "    combined_pcd[idx],\n",
    "    # combined_rgb[idx],\n",
    "    combined_pca_clip_rgb[idx],\n",
    "    # torch.ones_like(mask[idx]),\n",
    "    combined_mask[idx],\n",
    "    # special_points=torch.cat([tcp_pos, trajectory, goal_pos[:1]], dim=0),\n",
    "    # special_point_colors=torch.cat([tcp_rgb, trajectory_rgb, goal_rgb[:1]], dim=0),\n",
    ")\n",
    "fig = render_masked_3d_scatter(x, y, z, color)\n",
    "fig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_weights(points, mask, center, inverse_power=2):\n",
    "    # Calculate the distance of each point in combined_pcd from S\n",
    "    distances = torch.linalg.vector_norm(\n",
    "        points - center.reshape(-1, 1, 3), dim=2\n",
    "    )  # b, n_points, c\n",
    "\n",
    "    # Calculate weights inversely proportional to the distances\n",
    "    weights = 1 / (\n",
    "        distances**inverse_power + 1e-8\n",
    "    )  # Adding a small value to avoid division by zero\n",
    "\n",
    "    weights = mask * weights\n",
    "\n",
    "    weights = weights / weights.amax(dim=1, keepdim=True)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bounding_box_volume(pcd, keep_mask=None):\n",
    "    # Find the minimum and maximum coordinates along each axis\n",
    "    # pcd (b, npoints, 3)\n",
    "    if keep_mask is None:\n",
    "        pcd_for_min = pcd\n",
    "        pcd_for_max = pcd\n",
    "    else:\n",
    "        pcd_for_min = pcd.clone()\n",
    "        pcd_for_min[~keep_mask] = float(\"inf\")\n",
    "        pcd_for_max = pcd.clone()\n",
    "        pcd_for_max[~keep_mask] = float(\"-inf\")\n",
    "\n",
    "    min_coords = torch.amin(pcd_for_min, dim=1)\n",
    "    max_coords = torch.amax(pcd_for_max, dim=1)\n",
    "\n",
    "    # Calculate the side lengths of the bounding box along each axis\n",
    "    side_lengths = max_coords - min_coords  # Shape: (b,3)\n",
    "\n",
    "    # Calculate the volume of the bounding box\n",
    "    volumes = torch.prod(side_lengths, dim=1)  # Shape: (b,)\n",
    "\n",
    "    return volumes\n",
    "\n",
    "\n",
    "def camera_volume_weights(pcd, separate_mask=None):\n",
    "    volumes = {\n",
    "        cam: calculate_bounding_box_volume(pcd[cam], separate_mask[cam]).reshape(-1, 1)\n",
    "        for cam in pcd\n",
    "    }\n",
    "    stacked_volumes = torch.cat([volumes[cam] for cam in pcd], dim=1).reshape(-1, len(pcd), 1)\n",
    "    volumes = {cam: volumes[cam] / (stacked_volumes.amax(dim=1) + 1e-6) for cam in pcd}\n",
    "\n",
    "    if separate_mask is not None:\n",
    "        combined_weights = torch.cat(\n",
    "            [separate_mask[cam] * volumes[cam] for cam in pcd], dim=1\n",
    "        )\n",
    "    else:\n",
    "        combined_weights = torch.cat([volumes[cam] for cam in pcd], dim=1)\n",
    "    return combined_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.geometry as dgl_geo\n",
    "\n",
    "\"\"\"\n",
    "Fazit: torch_fpsample is pretty efficient, but rn only works on cpu\n",
    "                    CPU     GPU\n",
    "    DGL:             27s     1s\n",
    "    torch_fpsample: 0.4s     NA\n",
    "\n",
    "So it seems like we should pass data to cpu??? in the middle of training\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_fps(pcd, n_samples, mask=None):\n",
    "    pcd = pcd.to(\"cuda\")\n",
    "    pcd = pcd.clone()\n",
    "    if mask is not None:\n",
    "        mask = mask.to(\"cuda\")\n",
    "        # pcd[~mask] = float('inf') # works fine with dgl, not with quickfps\n",
    "        pcd[~mask] = 0  # works fine with both\n",
    "\n",
    "    sampled_inds = dgl_geo.farthest_point_sampler(\n",
    "        pcd,\n",
    "        n_samples,\n",
    "        0,\n",
    "    ).long()\n",
    "\n",
    "    # _, sampled_inds = torch_fpsample.sample(pcd, n_samples)\n",
    "\n",
    "    return sampled_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from manten.agents.utils.normalization import T3DMinMaxScaler\n",
    "\n",
    "# Define the specific point S\n",
    "# S = torch.tensor([0.0, 0.0, 0.0])\n",
    "S = tcp_pos\n",
    "\n",
    "pcd_a_s = dataset_info[\"pcd_stats\"]\n",
    "scaler = T3DMinMaxScaler(**pcd_a_s, preserve_aspect_ratio=True)\n",
    "\n",
    "tcp_pos = data[\"observations\"][\"state_obs\"][\"tcp_pose\"][\n",
    "    ..., :3\n",
    "]  # shape: (obs_horizon, 7) (position + quaternion)\n",
    "tcp_rgb = torch.tensor([1.0, 0.0, 0.0]).expand(tcp_pos.shape)\n",
    "\n",
    "delta_trajectory = data[\"actions\"][..., :3] * 0.1\n",
    "# delta_trajectory = data['actions'][..., :3]\n",
    "# delta_trajectory = inv_scale_action(data[\"actions\"][..., :3], -1, 1)\n",
    "\n",
    "scaled_pcd = scaler.scale(combined_pcd)\n",
    "tcp_pos = scaler.scale(tcp_pos)\n",
    "delta_trajectory = scaler.scale_without_translation(delta_trajectory)\n",
    "\n",
    "# # cumsum only works for !target! delta, not delta with current position\n",
    "trajectory = torch.cat([tcp_pos[:1, :3], delta_trajectory], dim=0).cumsum(dim=0)\n",
    "\n",
    "\n",
    "# volume_w = camera_volume_weights(pcd, mask)\n",
    "# # volume_w = camera_volume_weights(pcd, optree.tree_map(lambda x: torch.ones_like(x), mask))\n",
    "# distance_w = distance_weights(combined_pcd, combined_mask, S, inverse_power=0.5)\n",
    "# one = torch.ones_like(distance_w)\n",
    "\n",
    "# volume_normed_distance_w = (volume_w * 1) / (volume_w * 1).sum(dim=1, keepdim=True)\n",
    "\n",
    "# # sample_indices = torch.multinomial(volume_normed_distance_w, 128*128, replacement=False)\n",
    "# sample_indices = torch.multinomial(volume_normed_distance_w, 2048, replacement=False)\n",
    "\n",
    "print(combined_pcd.shape)\n",
    "\n",
    "sample_indices = run_fps(\n",
    "    combined_pca_clip_rgb, combined_pca_clip_rgb.shape[1] // 3, mask=combined_mask\n",
    ")\n",
    "sample_indices = sample_indices.to(\"cpu\")\n",
    "\n",
    "sample_mask = torch.zeros(combined_pcd.shape[:-1]).scatter(1, sample_indices, 1).bool()\n",
    "\n",
    "# f_mask = combined_mask\n",
    "# f_mask = combined_mask & sample_mask\n",
    "f_mask = sample_mask\n",
    "\n",
    "# frames = []\n",
    "# for idx in range(0, len(pcd[\"camera1\"]), 15):\n",
    "#     frames.append(get_scatter_trace(\n",
    "#         scaled_pcd[idx],\n",
    "#         combined_rgb[idx],\n",
    "#         f_mask[idx],\n",
    "#         special_points=torch.cat([tcp_pos, trajectory, goal_pos[:1]], dim=0),\n",
    "#         special_point_colors=torch.cat([tcp_rgb, trajectory_rgb, goal_rgb[:]], dim=0),\n",
    "#     ))\n",
    "# fig = render_masked_3d_scatter(*frames[0], frames=frames[::1])\n",
    "\n",
    "scale_x_within_abs_1_mask_pcd = scaled_pcd[..., 0].abs() < 1\n",
    "\n",
    "f_mask = f_mask & scale_x_within_abs_1_mask_pcd\n",
    "\n",
    "idx = 0\n",
    "x, y, z, color = get_scatter_trace(\n",
    "    scaled_pcd[idx],\n",
    "    # combined_rgb[idx],\n",
    "    combined_pca_clip_rgb[idx],\n",
    "    # torch.ones_like(f_mask[idx]),\n",
    "    f_mask[idx],\n",
    "    special_points=torch.cat([tcp_pos, goal_pos[:1]], dim=0),\n",
    "    special_point_colors=torch.cat([tcp_rgb, goal_rgb[:1]], dim=0),\n",
    ")\n",
    "fig = render_masked_3d_scatter(x, y, z, color)\n",
    "fig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False)\n",
    "fig.show()\n",
    "0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
