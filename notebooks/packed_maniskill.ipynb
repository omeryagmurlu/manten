{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch\n",
    "from optree import tree_map\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ManiSkillDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        pack_root,\n",
    "        task=\"PegInsertionSide-v1\",\n",
    "        obs_horizon=2,\n",
    "        pred_horizon=16,\n",
    "        obs_modalities=(\"pcd_obs\", \"rgb_obs\", \"state_obs\"),\n",
    "    ):\n",
    "        self.obs_modalities = obs_modalities\n",
    "\n",
    "        self.paths = {\n",
    "            \"action_lengths\": f\"{pack_root}/{task}/traj_lengths.npy\",\n",
    "            \"episode_format\": f\"{pack_root}/{task}/episode_%d.npz\",\n",
    "        }\n",
    "\n",
    "        action_lengths = np.load(self.paths[\"action_lengths\"])\n",
    "        action_lengths = action_lengths[np.argsort(action_lengths[:, 0])]\n",
    "\n",
    "        self.pad_action_arm = None\n",
    "\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.obs_horizon = obs_horizon\n",
    "        self.slices = []\n",
    "        total_transitions = 0\n",
    "        for (\n",
    "            episode_idx,\n",
    "            action_length,\n",
    "        ) in action_lengths:  # for each ep, so 30 in demo, do sliding windows\n",
    "            total_transitions += action_length\n",
    "\n",
    "            # |o|o|                             observations: 2\n",
    "            # | |a|a|a|a|a|a|a|a|               actions executed: 8\n",
    "            # |p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
    "            pad_before = obs_horizon - 1\n",
    "            # Pad before the trajectory, so the first action of an episode is in \"actions executed\"\n",
    "            # obs_horizon - 1 is the number of \"not used actions\"\n",
    "            pad_after = pred_horizon - obs_horizon\n",
    "            # Pad after the trajectory, so all the observations are utilized in training\n",
    "            # Note that in the original code, pad_after = act_horizon - 1, but I think this is not the best choice\n",
    "            self.slices += [\n",
    "                (episode_idx, start, start + pred_horizon)\n",
    "                for start in range(-pad_before, action_length - pred_horizon + pad_after)\n",
    "            ]  # slice indices follow convention [start, end)\n",
    "\n",
    "        print(\n",
    "            f\"Total transitions: {total_transitions}, Total obs sequences: {len(self.slices)}\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        traj_idx, start, end = self.slices[index]\n",
    "        episode = self.get_episode(traj_idx)\n",
    "        L, act_dim = episode[\"actions\"].shape\n",
    "\n",
    "        obs_seq = tree_map(\n",
    "            lambda obs: obs[max(0, start) : start + self.obs_horizon], episode[\"observations\"]\n",
    "        )\n",
    "        # start+self.obs_horizon is at least 1\n",
    "        act_seq = episode[\"actions\"][max(0, start) : end]\n",
    "        if start < 0:  # pad before the trajectory\n",
    "            obs_seq = tree_map(\n",
    "                lambda obs: torch.cat(\n",
    "                    [einops.repeat(obs[0], \"... -> k ...\", k=-start), obs], dim=0\n",
    "                ),\n",
    "                obs_seq,\n",
    "            )\n",
    "            act_seq = torch.cat([act_seq[0].repeat(-start, 1), act_seq], dim=0)\n",
    "        if end > L:  # pad after the trajectory\n",
    "            gripper_action = act_seq[-1, -1]\n",
    "            if self.pad_action_arm is None:\n",
    "                self.pad_action_arm = torch.zeros((act_dim - 1,))\n",
    "            pad_action = torch.cat((self.pad_action_arm, gripper_action[None]), dim=0)\n",
    "            act_seq = torch.cat([act_seq, pad_action.repeat(end - L, 1)], dim=0)\n",
    "            # making the robot (arm and gripper) stay still\n",
    "        for obs in obs_seq.values():\n",
    "            assert obs.shape[0] == self.obs_horizon\n",
    "        assert act_seq.shape[0] == self.pred_horizon\n",
    "\n",
    "        # |o|o|                             observations: 2\n",
    "        # |p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
    "        #\n",
    "        # | |a|a|a|a|a|a|a|a|               actions executed: 8\n",
    "        return {\n",
    "            \"observations\": obs_seq,\n",
    "            \"actions\": act_seq,\n",
    "        }\n",
    "\n",
    "    @functools.lru_cache(maxsize=100)  # noqa: B019\n",
    "    def get_episode(self, idx):\n",
    "        # this cache is bad since it is inflated by ddp_gpus * num_workers in memory\n",
    "        # shared memory would solve it but im lazy, so lru_cache it is\n",
    "        npz = np.load(self.paths[\"episode_format\"] % idx)\n",
    "        dc = {k: npz[k] for k in npz}\n",
    "        dc = tree_map(torch.from_numpy, dc)\n",
    "\n",
    "        obs_dict = {}\n",
    "        for modality in self.obs_modalities:\n",
    "            if modality == \"pcd_obs\":\n",
    "                obs_dict[modality] = dc[\"obs.pointcloud.xyzw\"].view(-1, 2, 128, 128, 4)\n",
    "            elif modality == \"rgb_obs\":\n",
    "                obs_dict[modality] = dc[\"obs.pointcloud.rgb\"].view(-1, 2, 128, 128, 3)\n",
    "            elif modality == \"state_obs\":\n",
    "                obs_dict[modality] = torch.cat(\n",
    "                    [dc[\"obs.agent.qpos\"], dc[\"obs.agent.qvel\"], dc[\"obs.extra.tcp_pose\"]],\n",
    "                    dim=1,\n",
    "                )\n",
    "\n",
    "        return {\n",
    "            \"actions\": dc[\"actions\"],\n",
    "            \"observations\": obs_dict,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an instance of the dataset\n",
    "pack_root = \"/home/i53/student/yagmurlu/code/manten/data/maniskill2/packed_demos\"\n",
    "dataset = ManiSkillDataset(pack_root=pack_root, obs_modalities=[\"rgb_obs\"])\n",
    "\n",
    "# Sample some data\n",
    "sample_index = 0  # Change this index to sample different data points\n",
    "sample = dataset[sample_index]\n",
    "\n",
    "print(tree_map(lambda x: x.shape, sample))\n",
    "\n",
    "\n",
    "# Display the RGB observation image\n",
    "rgb_obs = sample[\"observations\"][\"rgb_obs\"][0, 0].numpy()\n",
    "\n",
    "plt.imshow(rgb_obs)\n",
    "plt.title(\"RGB Observation\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
