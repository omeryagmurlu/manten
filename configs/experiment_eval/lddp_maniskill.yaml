# @package _global_

agent_creation:
  load_agent_kwargs:
    # train_folder: /home/i53/student/yagmurlu/code/manten/outputs/training/manten_maniskill_PegInsertionSide-v1/2024-12-25/21-11-33/accelerate
    train_folder: /home/i53/student/yagmurlu/code/manten/outputs/training/manten_maniskill_PickCube-v1/2024-12-26/01-04-10/accelerate
    checkpoint: checkpoint_5
  agent_wrapper:
    _target_: manten_evaluation.maniskill2.agent_wrappers.lddp.LDDPAgentWrapper
    obs_mode: ${evaluator.env_kwargs.obs_mode}
    device: ${device}

evaluator:
  _target_: manten_evaluation.maniskill2.lib.evaluation.ManiskillEvaluation
  num_eval_episodes: 60
  num_envs: 15
  sim_backend: cpu
  # env_id: PegInsertionSide-v1
  env_id: PickCube-v1
  env_kwargs:
    control_mode: pd_ee_delta_pose
    reward_mode: sparse
    obs_mode: state
    render_mode: rgb_array
    # max_episode_steps: 300
    max_episode_steps: 100
  wrappers:
    - _target_: manten_evaluation.maniskill2.lib.utils_wrappers.TreeFrameStack
      _partial_: True
      num_stack: 2 # change this to match agent
  action_executor:
    _target_: manten_evaluation.maniskill2.lib.utils_wrappers.HorizonActionExecutor
  save_video: True

hydra:
  run:
    dir: ./outputs/maniskill-eval/${evaluator.env_id}-max_steps-${evaluator.env_kwargs.max_episode_steps}-${evaluator.env_kwargs.control_mode}-${evaluator.env_kwargs.obs_mode}/${now:%Y-%m-%d}/${now:%H-%M-%S}-${evaluator.sim_backend}
