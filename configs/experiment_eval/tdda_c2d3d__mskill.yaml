# @package _global_

defaults:
  - /tasks/maniskill_tasks@task_spec: pick_cube_v1

agent_creation:
  load_agent_kwargs:
    train_folder: /home/i53/student/yagmurlu/code/manten/outputs/training/manten_maniskill_PickCube-v1/2025-01-13/02-44-03/accelerate
    use_ema: False
  agent_wrapper:
    _target_: manten_evaluation.maniskill2.agent_wrappers.lddp.LDDPAgentWrapper
    obs_mode: ${evaluator.env_kwargs.obs_mode}
    state_modality_keys: ${task_spec.state_modality_keys_with_tcp_pose}
    rgb_modality_keys: ${task_spec.rgb_modality_keys}
    rotation_transform: rotation_6d
    device: ${device}
    meta_2d_3d_mask: 2d

evaluator:
  _target_: manten_evaluation.maniskill2.lib.evaluation.ManiskillEvaluation
  num_eval_episodes: 60
  num_envs: 15
  sim_backend: ${task_spec.sim_backend}
  env_id: ${task_spec.env_id}
  env_kwargs:
    control_mode: pd_ee_delta_pose
    reward_mode: sparse
    obs_mode: pointcloud
    render_mode: rgb_array
    # max_episode_steps: 300
    max_episode_steps: 100
  wrappers:
    - _target_: manten_evaluation.maniskill2.lib.utils_wrappers.TreeFrameStack
      _partial_: True
      num_stack: 1 # change this to match agent
  action_executor:
    _target_: manten_evaluation.maniskill2.lib.utils_wrappers.HorizonActionExecutor
  save_video: True

hydra:
  run:
    dir: ./outputs/maniskill-eval/${evaluator.env_id}-${agent_creation.agent_wrapper.meta_2d_3d_mask}-max_steps-${evaluator.env_kwargs.max_episode_steps}-${evaluator.env_kwargs.control_mode}-${evaluator.env_kwargs.obs_mode}/${now:%Y-%m-%d}/${now:%H-%M-%S}-${evaluator.sim_backend}
